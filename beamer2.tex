\documentclass{beamer}

\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[francais]{babel}
\usepackage[english]{babel}
\uselanguage{French}
\usepackage{dsfont}
\usepackage{bbold}
\usepackage{stmaryrd}
\languagepath{French}
\usepackage{xcolor}

\usepackage{pgf}
\usepackage{tikz}


\mode<presentation> {
\usetheme{AnnArbor}

\setbeamercovered{transparent}
\definecolor{rouge}{RGB}{255,0,0}
\definecolor{almond}{rgb}{0.94, 0.87, 0.8}
\definecolor{blue(pigment)}{rgb}{0.2, 0.2, 0.6}
\definecolor{or}{RGB}{255,204,0}
\definecolor{cerise}{rgb}{0.87, 0.19, 0.39}
\definecolor{fandango}{rgb}{0.71, 0.2, 0.54}
\setbeamercolor{structure}{fg=rouge,bg=or}
\setbeamercolor{titlelike}{fg=noir,bg=or}
\setbeamercolor{frametitle}{fg=blue,bg=or}
\setbeamercolor{item}{fg=rouge,bg=or}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ Anova2F}
\author{\color{rouge} Khalifi Oumayma\\Walid Kandouci\\ Abdestar SAHBANE\\\color{fandango} M2 MIND ET BIOSTAT}

\institute{Faculté des sciences Montpellier}

\date{\today}




\begin{document}

% page titre
\begin{frame}
\titlepage
\end{frame}

% plan de la présentation
\begin{frame}
\frametitle{Summary}
\tableofcontents
\end{frame}


\section{Introduction}
\begin{frame}
\frametitle{Introduction}
We discussed in the previous paragraph the one-way ANOVA and its uses.
%that examines the influence of one categorical independent variables on another continuous dependent variable.\\
\\
In this paragraph, we will be looking at two-way ANOVA, an extension of the one-way ANOVA that examines the influence of two different categorical independent variables on one continuous dependent variable. \\
The two-way ANOVA not only aims at assessing the main effect of each independent variable but also if there is any interaction between them.
\end{frame}






\section{Exemple}


\begin{frame}
\frametitle{introductory example:}
Suppose we have two judges who do a tasting of 2 different wines, called Wine 1 and Wine 2 such as:\\
- Judge 1 does 7 tastings: 3 for Wine 1 and 4 for Wine 2.\\
- The judge 2 does 4 tastings: 3 for Wine 1 and 1 for Wine 2.
\end{frame}

\begin{frame}
\frametitle{introductory example:}
We summarize the example in the form of the following table:\\




If factor 1 is Judge 2 and factor 2 is Vin 1, we have :$$y_{211}=3, y_{212}=8, y_{213}=4 $$
Here, we have: \\$$n= n_{1 1}+n_{1 2}+n_{2 1}+n_{2 2}=3+4+3+1=11$$
we must adapt the table so as to have $n_{ij}$ = constant fixed $\forall i,j\in[\![1, 2]\!]$.
 This is done either by eliminating or adding elements.

\end{frame}

% partie 2 : page 2

\subsection{}
\begin{frame}
\frametitle{}
Two factors :\\
$\bullet$ Factor $1$ : $I$ levels / $I$ classes.\\
$\bullet$ Factor $2$ : $J$ levels / $I$ classes.\\

$n_{ij}$ : nombre of repetitions / observations of factor 1 in the $i$ classe and to factor $2$ in $j$ class.\\

We obtain the following constraints :
$$n=\sum_{i=1}^{I} \sum_{j=1}^{J} n_{i j}$$
\end{frame}

















\section{Model}
\begin{frame}{Model equation}
   
  
  
\begin{alertblock}{Model: }
  $$\left.y_{i, j, k} \stackrel{i i d}{\sim} \mathcal{N}\left(\mu_{i j}, \sigma^{2}\right), \quad \forall i \in[\![1, I]\!] , \forall j \in\left[\![1, J\right]\!] ,\forall k \in\left[\![1, n_{i j}\right]\!]$$\\
 
   $$y_{i, j, k}=\mu+\alpha_{i}+\beta_{j}+\varepsilon_{i, j, k}$$
   
\end {alertblock}
  
  \\ \\ \\
  
  
  %\\ \\We have:\\$$\left.y_{i, j, k} \stackrel{i i %d}{\sim} \mathcal{N}\left(\mu_{i j}, \sigma^{2}\right), %\quad \forall i \in[\![1, I]\!] , \forall j %\in\left[\![1, J\right]\!] ,\forall k \in\left[\![1, %n_{i j}\right]\!]$$\\
  % $$y_{i, j, k}=\mu+\alpha_{i}+\beta_{j}+\varepsilon_{i, %j, k}$$\\
  \begin{itemize}\\ \\

   \item $\operatorname{Cov}\left(\varepsilon_{i, j, k}, \varepsilon_{i^{\prime}, j^{\prime}, k^{\prime}}\right)=\sigma^{2} \delta_{i, i^{\prime}} \delta_{j, j^{\prime}} \delta_{k, k^{\prime}}$\\
   \item$  \mu \in \mathbb{R}$: the average effect.\\
   \item$\alpha_{i}$: the specific effect of level i for the first factor. \\
   \item$\beta_{j}$:the specific effect of level j for the second factor.
   \end{itemize}
\end{frame}










\begin{frame}{}

 
\textcolor{red}{\textbf{Note:}} \\
\\
\vspace{0.5cm}If the design of the experiment is not balanced (i.e., the $n_{i j}$ are different), the mathematical analysis is difficult.\\
\vspace{0.3cm}
We will therefore assume in order to facilitate the analysis:
\textcolor{red}{$$\forall i \in[\![1, I]\!], \quad \forall j \in[\![1, J]\!], \quad n_{i j}=K $$}\\

Finaly we get: $n=IJK$ observations.
\end{frame}


\begin{frame}{}   
We can write the model in matrix form just by  following a usual approach that is least squares:\\

\begin{alertblock}{}
\vspace{1cm}
\textcolor{red}{$$X=\left[\begin{array}{lllllll}
\mathbb{1}_{n} & \mathbb{1}_{C_{1}} & \ldots & \mathbb{1}_{C_{I}} & \mathbb{1}_{D_{1}} & \ldots & \mathbb{1}_{D_{J}}
\end{array}\right] \in \mathbb{R}^{n \times(1+I+J)}$$}
\end{alertblock}\\
Where:\\
$$\operatorname{rang}(X)=I+J+1-2=I+J-1 \text { et } \mathbb{1}_{n}=(1, \ldots, 1)^{\top}$$

\end{frame}








\begin{frame}{Definition}
\begin{alertblock}{}
$$\underset{(\mu, \alpha, \beta) \in \mathbb{R} \times \mathbb{R}^{I} \times \mathbb{R}^{J}}{\arg \min } \frac{1}{2} \sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{K}\left(y_{i, j, k}-\mu-\alpha_{i}-\beta_{j}\right)^{2}$$
$$\text {s.c.} \quad \sum_{i=1}^{I} \alpha_{i}=0$$
 $$\hspace{0.83cm} \sum_{j=1}^{J} \beta_{j}=0$$
\end{alertblock}
\end{frame}








\begin{frame}{}
For this problem we get the following Lagrangian:
\vspace{1cm}
\textcolor{red}{$$\mathcal{L}\left(\mu, \alpha, \beta, \lambda_{\alpha}, \lambda_{\beta}\right)=\frac{1}{2} \sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{K}\left(y_{i, j, k}-\mu-\alpha_{i}-\beta_{j}\right)^{2}+\lambda_{\alpha}\left(\sum_{i=1}^{I} \alpha_{i}\right)+\lambda_{\beta}\left(\sum_{j=1}^{J} \beta_{j}\right)$$}

\end{frame}


\begin{frame}{}
We should solve the following system:
\vspace{1cm}
$$\left\{\begin{array}{l}
\frac{\partial \mathcal{L}}{\partial \mu}=0 \\
\frac{\partial \mathcal{L}}{\partial \alpha}=0 \\
\frac{\partial \mathcal{L}}{\partial \beta}=0 \\
\frac{\partial \mathcal{L}}{\partial \lambda_{\alpha}}=0 \\
\frac{\partial \mathcal{L}}{\partial \lambda_{\beta}}=0
\end{array}\right.$$
\end{frame}


\begin{frame}{}
We get as results:
\vspace{0.5cm}
$$\frac{\partial \mathcal{L}}{\partial \mu}=0 \Longrightarrow n \widehat{\mu}=\sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{K} y_{i, j, k} \Longrightarrow \widehat{\mu}=\bar{y}_{n}$$
\vspace{0.5cm}
$$\hspace{0.8cm}\frac{\partial \mathcal{L}}{\partial \alpha}=0 \Longrightarrow \forall i \in[1, I], \quad \widehat{\alpha}_{i}=& \underbrace{\bar{y}_{i,:,}}_{=\frac{1}{J K} \sum_{j=1}^{N} \sum_{k=1}^{K} y_{i, j, k}}-\widehat{\mu}$$
\vspace{0.5cm}
$$\hspace{0.8cm}\frac{\partial \mathcal{L}}{\partial \beta}=0 \Longrightarrow \forall j \in[1, J], \widehat{\beta}_{j}=& \underbrace{\bar{y}_{:, j, \vdots}}_{=\frac{1}{I K}} \sum_{i=1}^{I} \sum_{k=1}^{K} y_{i, j, k}-\widehat{\mu}$$
\end{frame}










\begin{frame}{}
Associated predictor:
\vspace{0.5cm}
$$\widehat{y_{i j}} &=\widehat{\mu}+\widehat{\alpha_{i}}+\widehat{\beta}_{j}$$ \\
$$\hspace{0.89cm}&=\bar{y}_{i,:,:}+\bar{y}_{:, j,:}-\widehat{\mu} \\
$$\hspace{0.89cm}&=\bar{y}_{i,:,:}+\bar{y}_{:, j,:}-\bar{y}_{n}$$

\end{frame}

\begin{frame}{}
The affected unbiased estimator is:
\vspace{1cm}
$$\widehat{\sigma^{2}}=\frac{1}{n-(I+J-1)} \sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{K}\left(\widehat{y_{i j}}-y_{i, j, k}\right)^{2}$$
\vspace{0.5cm}

The estimator $\sigma^{2}$ is:
\vspace{1cm}
$$\hspace{-5cm}\mathbb{E}\left(\widehat{\sigma^{2}}\right)=\sigma^{2}$$
\end{frame}








\begin{frame}

Global test:
$$\text {\textbf {Facteur } 1:} H_{0}: "_{\alpha_{1}}=\alpha_{2}=\cdots=\alpha_{I} "$$


$$\text { \textbf{Facteur } 2:} H_{0}: " \beta_{1}=\beta_{2}=\cdots=\beta_{J} "$$

\end{frame}

\begin{frame}{}
For factor 1:
\vspace{0.5cm}
$$F_{o b s}=\frac{1}{\widehat{\sigma^{2}}} \frac{K J}{(I-1)} \sum_{i=1}^{I}\left(\bar{y}_{i, ; ;:}-\bar{y}_{n}\right)^{2} \sim \mathcal{F}_{n-(I+J-1)}^{I-1}$$

Test:
$F_{\text {obs}}>\mathcal{F}_{n-(I+J-1)}^{I-1}(1-\alpha)$
\end{frame}




\end{document}
